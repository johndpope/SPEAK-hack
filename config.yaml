# Model configuration
model:
  sample_size: 512
  in_channels: 3
  out_channels: 3
  center_input_sample: false
  time_embedding_type: "positional"
  model_channels: 192
  channel_mult: [1, 2, 3, 4]
  num_blocks: 3
  attn_resolutions: [16, 8]
  dropout: 0.1
  label_balance: 0.5
  concat_balance: 0.5

# Training configuration
training:
  output_dir: "./speak"
  num_epochs: 100
  train_batch_size: 2
  eval_batch_size: 16
  save_image_steps: 1000  # Save reconstructed image every 500 steps
  gradient_accumulation_steps: 1
  mixed_precision: "fp16"
  epochs_per_resolution: 1
  eval_steps: 1000
  logging_steps: 100
  P_mean: -0.4
  P_std: 1.0
  sigma_data: 0.5
  num_workers: 1
  val_batch_size: 32
  early_stopping_patience: 10
  grad_clip: true
  grad_clip_value: 1.0
  save_epochs: 1000
  log_steps: 100


# Dataset configuration
dataset:
  name: "lansinuote/gen.1.celeba"
  split: "train[:80%]"
  image_size: 64
  val_split: 0.2 # 10% of data for validation

# Optimization configuration
optimization:
  learning_rate: 1e-4
  lr_warmup_steps: 500
  num_train_timesteps: 1000
  beta_start: 0.0001
  beta_end: 0.02
  beta_schedule: "linear"
  lr_patience: 5  # Number of epochs with no improvement after which learning rate will be reduced
  
# Sampling configuration
sampling:
  num_inference_steps: 50
  guidance_scale: 7.5

# Logging and evaluation
logging:
  log_with: "tensorboard"
  project_name: "speak_training"


  # Sampler configuration
sampler:
  num_steps: 32
  sigma_min: 0.002
  sigma_max: 80
  rho: 7